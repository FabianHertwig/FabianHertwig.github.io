---
title: "Your Brain on Slot Machines: How Apps Exploit Ancient Survival Circuits"
date: 2026-01-02 18:00:00 +0200
categories:
  - blog
tags:
  - Psychology
  - Neuroscience
  - Technology
  - Addiction
  - Social Media
draft: true
---

You put your phone down, determined to focus on something else. Anything else. You have work to do, emails to send, a book you've been meaning to read. You set the phone face-down on the table, a small gesture of resolve.

Two minutes later, it's back in your hand. Thumb scrolling. You didn't consciously decide to pick it up. In fact, you specifically decided *not* to. And yet here you are, watching a video of a cat doing something moderately amusing, already forgetting why you picked up the phone in the first place.

If this sounds familiar, I have good news and bad news.

The bad news: you're not going to willpower your way out of this. The systems driving that behavior are ancient, powerful, and operate largely beneath conscious awareness.

The good news: once you understand *why* your brain does this, you can stop blaming yourself and start designing your environment differently. This isn't a character flaw. It's evolutionary biology meeting teams of engineers who've figured out exactly how to exploit it.

---

# Part 1: The Exploitation Playbook

Open TikTok. Swipe. Meh. Swipe. Meh. Swipe. Okay, that was kind of funny. Swipe. Meh. Swipe. Meh. Swipe. Meh. Swipe. Oh wow, that's actually amazing.

You just experienced the reward pattern that makes slot machines work. And it's not an accident.

Consider what TikTok is actually doing: most videos are mediocre, some are good, and occasionally one is perfect for you. You can't predict which swipe will pay off: **variable rewards**. The next video is one thumb movement away, with no searching, no deciding, no effort: **no friction**. The feed never ends, so there's no natural place to quit: **no stopping point**. And that video that was *almost* funny, that post that was *almost* interesting? Each one feels like progress toward the jackpot: **near-misses**.

This isn't just TikTok. Instagram Reels, YouTube Shorts, Twitter feeds, Tinder: same formula. Dating apps turn human connection into a swipe-based slot machine. Even browsing Netflix or YouTube's homepage is a kind of foraging through mediocre thumbnails hoping to strike gold. The pattern is everywhere once you see it.

Why does it work so well? The answer starts with a psychologist, some pigeons, and casinos that figured out the formula before the science existed.

---

# Part 2: The Science of Why It Works

## Skinner's Pigeons

In the 1950s, B.F. Skinner was studying how animals learn. He'd put pigeons in specially designed boxes (now called Skinner boxes) with a lever they could peck. Peck the lever, get food.

As Skinner later told it, he stumbled onto something unexpected while running low on food pellets. When rewards came predictably (every peck, or every tenth peck) the pigeons behaved predictably too. They'd peck, eat, take breaks. Sensible birds.

But when rewards came randomly? Sometimes on the third peck, sometimes on the twentieth, sometimes twice in a row? The pigeons became obsessive, pecking with manic persistence, far more than under any predictable schedule. Skinner had discovered **variable ratio reinforcement**: random rewards for repeated actions.

In 1957, Skinner and his colleague C.B. Ferster published *Schedules of Reinforcement*, which formalized these findings through rigorous experimentation. But when Skinner wrote about gambling in 1953, he noted something interesting: "the efficacy of such schedules in generating high rates has long been known to the proprietors of gambling establishments."

The casinos had figured it out empirically before the science caught up.

## How Casinos Engineered Addiction

How did casino owners discover the optimal formula for addiction without running controlled experiments on pigeons? To answer that, we need to go back before slot machines existed at all.

In 1891, Sittman and Pitt of Brooklyn, New York built a gambling machine that used five spinning drums, each holding ten playing cards. It was essentially mechanized poker. Players would insert a nickel, pull a lever, and hope the drums landed on a good poker hand. There was no automatic payout; you'd show your result to the bartender and collect your prize (usually free drinks or cigars). The machine was wildly popular. Within a few years, nearly every bar in New York had one.

But notice what this machine *didn't* have: drama. All five drums stopped at roughly the same time. You either got a good hand or you didn't. There was no "almost."

A few years later, Charles Fey, a Bavarian immigrant working as a mechanic in San Francisco, saw an opportunity. He'd been tinkering with coin-operated machines for years, and in 1898 he built something different: the Liberty Bell.

Fey's design made three key changes. First, he replaced the five poker drums with three simpler reels, each showing just five symbols (horseshoes, diamonds, spades, hearts, and liberty bells). This made outcomes easier to read and allowed for automatic payouts, since the machine only needed to recognize a few winning combinations instead of every possible poker hand.

Second, and more importantly, he made the reels stop sequentially. The first reel lands: cherry. The second reel lands: cherry. The third reel is still spinning... then it lands: lemon. *You were so close.*

This delay was the innovation that mattered. Fey had accidentally built the near-miss into the physical structure of the machine. Earlier color-wheel machines showed their result all at once, which meant you could calculate your odds from what you saw. With three sequential reels showing just a fraction of the thousand possible combinations (10 × 10 × 10), players had no way to calculate the payout percentage. And more crucially, the sequential stopping created suspense and the feeling of "almost winning" that the poker machines lacked.

The Liberty Bell was enormously successful. Because gambling was illegal in California, Fey couldn't patent his device, and competitors immediately began copying it. Within a decade, slot machines were everywhere.

But the real engineering came later. In 1983, when computerized slots replaced mechanical reels, designers gained precise control over probabilities. They developed a technique called "virtual reel mapping," where the physical symbols you see spinning don't correspond to the actual odds. A jackpot symbol might appear on the physical reel as often as any other, but in the computer's virtual reel (which determines outcomes), it appears far less frequently.

More insidiously, designers began using "clustering," deliberately placing blank stops next to jackpot symbols on the virtual reel. The result: when you lose, you frequently see the jackpot symbol *just above* or *just below* the payline. A near-miss. Your brain registers it as "almost," even though the computer had already determined you'd lost the instant you pulled the lever.

This wasn't subtle. In 1988, a case came before the Nevada Gaming Commission challenging one manufacturer's algorithms for generating an artificially high rate of near-misses. The commission ruled that certain techniques were "unacceptable," but notably, virtual reel mapping that creates near-misses above and below the payline remains legal to this day.

The casinos didn't need Skinner's research to design addictive machines. They had something better: direct feedback on what keeps people pulling the lever, refined over a century. What Fey stumbled onto with sequential reels, modern designers have turned into a science.

## The Near-Miss Trick

In 2009, Luke Clark and colleagues at Cambridge put volunteers in brain scanners and had them play slot machines. When someone won, their reward circuits lit up, specifically the ventral striatum, the same region that responds to food and sex. When someone *almost* won (cherry-cherry-lemon) their reward circuits also lit up. Almost as much as a real win.

Your brain treats "I almost got it!" as genuine progress. This would be sensible if slot machines were skill-based games where getting close meant you were improving. But they're not. The outcome is determined the instant you pull the lever. Cherry-cherry-lemon is exactly as informative as lemon-lemon-lemon: you lost.

Yet your brain thinks: "I was so close! Next time!"

Research suggests near-miss rates around 30% maximize persistence: high enough to maintain hope, not so high that the manipulation becomes obvious. Modern slot machines are engineered to hit roughly this rate.

Now think about your feed. That video that was *almost* funny. That profile on Tinder that was *almost* your type. That thread that was *almost* insightful. Each near-miss keeps you swiping, because your brain registers it as progress toward the jackpot.

## Schultz's Monkeys

Skinner showed *what* kept animals hooked. But it took another few decades to understand *how* the brain actually processes these rewards.

In the 1990s, Wolfram Schultz at Cambridge was studying monkeys. He wanted to understand dopamine, the neurotransmitter that everyone at the time assumed was the "pleasure chemical." The thinking went like this: you eat something delicious, dopamine releases, you feel pleasure. Simple cause and effect.

Schultz designed an experiment to test this. A monkey reaches into a box, finds a treat. He recorded what the dopamine neurons were doing. At first, the neurons fired when the monkey got the treat. If dopamine equals pleasure, this confirmed the theory.

But then he noticed something that didn't fit. After the monkey learned that the box always contained a treat, the dopamine response *shifted*. Now the neurons fired when the monkey *saw* the box, not when it got the treat. The actual reward barely registered anymore.

And when the monkey expected a treat but didn't get one? The dopamine neurons went *below* baseline, a negative signal. When it expected nothing but got a treat anyway? A huge spike.

Schultz realized he wasn't looking at a pleasure signal. He was looking at a **prediction error** signal. In a 1997 paper that changed the field, he showed that dopamine tracks the gap between what you expected and what you got:

- Better than expected → dopamine spike
- As expected → nothing
- Worse than expected → dopamine dip

This explains why your tenth bite of cake is less exciting than your first, even though the taste is identical. The first bite exceeded prediction. The tenth matched it. Same cake, different signal.

And it explains why variable rewards are so compelling. When you can't predict whether the next swipe will be good or bad, every swipe generates potential prediction error. Your dopamine system stays engaged, perpetually anticipating the possibility of surprise.

## Berridge's Rats

Around the same time Schultz was studying monkeys, Kent Berridge at the University of Michigan was studying rats and sweet tastes. Normal rats, when you give them sugar water, make a characteristic facial expression, a "yum" face that looks remarkably similar across mammals, including human babies.

Berridge tried something extreme: he destroyed most of the dopamine system in these rats. If dopamine was the pleasure chemical, these rats shouldn't enjoy sugar anymore.

But they still liked sugar. When it touched their tongues, they made the same "yum" face. The pleasure was intact. What was gone was any motivation to seek it out. They'd walk right past a pile of sugar and starve to death. If you put sugar in their mouths, they'd happily consume it. They just wouldn't go get it.

Berridge had discovered that **wanting** and **liking** are separate systems in the brain. Dopamine doesn't make you enjoy things. It makes you *want* things. It generates what Berridge calls "incentive salience," the feeling that something is worth pursuing. The actual enjoyment comes from different, smaller neural circuits involving opioids.

This separation is what makes certain behaviors so insidious. You can want something intensely while barely enjoying it when you get it.

Think about checking your phone. You feel a pull to check it. That's wanting, dopamine signaling that something potentially rewarding might be there. You check. Mostly nothing interesting. You don't particularly enjoy the experience. But a few minutes later, you feel the pull again. The wanting returns, even though the liking never showed up.

Or think about eating chips from a bag. You're not savoring each chip. They're fine. But you keep reaching for the next one, and the next one, and suddenly the bag is empty and you feel vaguely sick. The wanting drove the behavior. The liking was barely involved.

Berridge has described addiction as "a starved want in an unstarved brain," the wanting mechanism running at full intensity while the liking mechanism provides no corresponding satisfaction. App designers don't need you to enjoy their product. They just need you to keep wanting to check it.

## The Foraging Brain

Why does your brain fall for this? Because these systems weren't designed for the modern world. They were designed for finding food when you don't know where it is.

Imagine you're a proto-human on the African savanna. Food is scattered unpredictably across the landscape. Some bushes have berries, most don't. Some areas have tubers, but you have to dig to find out. Some paths lead to watering holes where you might catch prey, or you might waste hours finding nothing.

Most of your attempts fail. And they have to fail. If food were easy to find, it would already be gone. Your survival depends on persistence through endless disappointment.

The dopamine system evolved to solve this problem. It rewards the search, not just the find. It makes the *possibility* of finding something almost as motivating as actually finding it. Your ancestors who kept exploring (one more bush, one more trail, one more dig) occasionally hit jackpots: a carcass, a honeycomb, a patch of ripe fruit. Those who gave up too easily starved.

But there's a second adaptation that's crucial to understanding why these systems are so exploitable. If every failed attempt felt as bad as a successful find felt good, you'd be too demoralized to continue after three empty bushes. So the brain evolved an asymmetry: wins register strongly, losses barely register at all.

Finding food creates an intense, memorable spike. Not finding food is just... neutral. Not painful. Just nothing. You shrug it off and keep searching.

This asymmetry is exactly what gambling exploits. You lose ten times, and each loss barely registers. Then you win once, and the spike feels significant. Your brain does bad accounting: the one win looms larger than the ten losses. You keep playing.

These systems are ancient. Dopamine-based reward circuits aren't unique to humans; they exist in insects, fish, even worms. When you feel the compulsive urge to check your phone, you're fighting hundreds of millions of years of optimization.

But the foraging environment had built-in limits. You had to walk miles. You could only carry so much back to camp. You could only eat so much before you were full. The search eventually ended.

Modern technology has removed all of these limits. "Rewards" are infinite. The effort is negligible, just moving your thumb. There's no upper bound, no natural stopping point. Your brain cannot tell the difference between "I found food that will keep my family alive" and "I found an entertaining video." Both trigger the same ancient system. Both feel like something. But one matters. The other just consumed twenty minutes of your life.

---

# Part 3: What's New

Skinner's research is from the 1950s. Schultz's key papers came out in 1997. You might wonder: have we learned anything new? We have, and it makes the picture more concerning.

TikTok's algorithm isn't like Skinner's random reinforcement schedule, and it's not like a slot machine's fixed probabilities. It's something more sophisticated: the slot machine is learning you.

Classic variable reinforcement is random. The pigeon gets food on an unpredictable schedule, but the schedule isn't personalized. A slot machine pays out based on fixed probabilities that apply to everyone equally.

TikTok's For You page is different. It's watching which videos make you pause, which ones you watch to the end, which ones you rewatch, which ones you skip past immediately. It's building a model of your specific dopamine triggers and then optimizing for them. This is variable rewards calibrated to *your* prediction error system.

This is why people describe the For You page as eerily accurate, like the app knows them better than they know themselves. It's not just showing you random content hoping something lands. It's testing, learning, and refining what works for you specifically.

Research on TikTok has identified something called the "flow experience," a state of absorption where you lose track of time and become fully immersed in the content stream. The key predictor of problematic use isn't just the variable rewards; it's this trance-like concentration where minutes slip into hours without your awareness. Studies show that people underestimate the time they spend on TikTok more than on other platforms.

This isn't just academic speculation anymore. In October 2024, thirteen U.S. states and the District of Columbia sued TikTok, alleging that its algorithm is "designed to promote excessive, compulsive, and addictive use" in children. The lawsuit claims TikTok's design deliberately exploits dopamine reward circuitry. Whether or not the legal case succeeds, the fact that it exists signals something: the mechanisms we've been discussing have moved from psychology journals into courtrooms.

---

# Part 4: Breaking Free

So what do you do with this knowledge?

The first thing to understand is that willpower is not the answer. You're not going to think your way out of systems that operate below conscious awareness and that have been optimized over hundreds of millions of years of evolution.

But you can change the environment.

## Understanding Your Triggers

Cognitive Behavioral Therapy (CBT) is a therapeutic approach that helps people identify the thoughts and situations that trigger problematic behaviors. Rather than trying to suppress urges through sheer willpower, CBT focuses on noticing the patterns: what happens right before the behavior? What internal state are you in? What are you trying to avoid or achieve?

In trials with smartphone-addicted adolescents, 12-week CBT programs significantly reduced addiction scores. The most helpful module, according to participants, was called "Recognize the Triggers," which taught people to notice *why* they were reaching for their phone in the first place.

The insight is that phone checking isn't random. It's triggered by specific internal states: boredom, loneliness, anxiety, the desire to escape an uncomfortable task, the need for stimulation. If you can notice *why* you're reaching for the phone, you create a moment of choice that wasn't there before.

Some questions to ask yourself in that moment: Am I feeling bored? What am I avoiding? Am I feeling lonely? What connection am I actually seeking? Am I feeling anxious? What would actually address the anxiety? And perhaps most useful, given what we know about wanting versus liking: will I actually enjoy this, or am I just responding to a pull?

That last question is worth developing into a practice. Before you check your phone, predict: "Will I feel better after 10 minutes of scrolling?" Then afterward, notice whether your prediction was accurate. Building this awareness helps reveal the gap between the pull and the payoff, the wanting that persists even when liking never shows up.

## Environmental Design

The more effective approach is to change the environment so the behavior becomes harder in the first place. You're not going to out-think systems that have been optimized for millions of years. But you can redesign the choice architecture so that checking your phone requires more effort than not checking it.

The simplest intervention is turning off notifications. Every notification is a trigger, every buzz is your phone asking for attention. Most apps default to aggressive notification settings because their metric is engagement, not your wellbeing. Turn off notifications for everything except calls and messages from actual humans, and you've eliminated hundreds of daily triggers.

The next step is removing apps from your home screen. If you have to search for an app to open it, you've added a few seconds of friction. That small delay creates a moment where you can ask "Do I actually want to do this?" Having Instagram's icon staring at you every time you unlock your phone is a cue that triggers wanting. Remove the cue and you remove the trigger.

For deeper focus, put your phone in another room entirely. A 2017 study from UT Austin found that participants with their phones in another room significantly outperformed those with phones on the desk, even when the phones were face-down and silent. Just having the phone nearby seemed to occupy cognitive resources. Part of your brain was dedicated to *not* checking it, and that effort cost something. (A 2024 meta-analysis of 33 studies found smaller effects than the original study, suggesting this may vary by individual, but even a small effect compounds over time.)

A more aggressive intervention is grayscale mode. Research shows that switching your display to grayscale reduces daily screen time by 20-50 minutes. The mechanism is simple: colorful visuals trigger dopamine responses. App icons and notification badges are designed with bright, saturated colors specifically because those colors grab attention. Remove the colors, and the phone becomes less visually compelling. Your brain is less drawn to a gray Instagram icon than a vibrant one. Some users find grayscale hard to maintain long-term, but even using it intermittently, say after 9pm, can help.

Other friction techniques include logging out of apps after each use (having to re-enter a password creates a pause that's often enough to break the automatic behavior) and using browser versions instead of apps (the mobile web version of Twitter or Instagram is clunkier, slower, and less optimized for addiction, which is a feature, not a bug).

For some people, friction isn't enough. Deleting the apps entirely is the only thing that works. If you find yourself reinstalling apps you've deleted, that's useful information about how strong the pull is.

## Making Losses Visible

Remember the foraging asymmetry: wins register strongly, losses fade. One way to counter this is to make the losses visible.

Screen time tracking does this automatically. Seeing "4 hours 23 minutes on TikTok" at the end of the day is information your brain would otherwise ignore. You might not remember the scrolling (each mediocre video faded from memory as soon as it passed) but you'll notice the number.

Some people find journaling useful: after a scrolling session, write down what you actually got from it. Often the answer is "nothing" or "I feel worse." Recording this counters the brain's tendency to remember the occasional good video and forget the hundred forgettable ones.

---

# Part 5: Using It For Good

If these mechanisms are so powerful, can they be used for good? Can you get addicted to working out, or to learning, or to doing deep work?

The answer is yes, with an important caveat: engagement is not the same as effectiveness. The mechanisms that keep you coming back are not necessarily the mechanisms that help you achieve your goals.

## The Duolingo Problem

Duolingo is often cited as an example of ethical gamification. It uses many of the same mechanisms as exploitative apps: streaks (miss a day and lose your progress), variable rewards (XP and achievements), leaderboards (compete against strangers), and notifications (Duo the owl famously guilts you into returning). And it works: users keep coming back. Daily active users represent about a third of monthly active users, engagement numbers that most apps can't touch.

But many people use Duolingo for years and still can't hold a conversation in their target language. The engagement is real. The learning outcomes are disputed.

This reveals an important distinction. Duolingo's streaks create habit formation. Whether those habits produce fluent speakers is a different question. You can be deeply engaged with something (checking it every day, maintaining a 500-day streak) while making minimal progress toward your actual goal.

The lesson: if you're trying to harness these mechanisms for good outcomes, you need to ask what the engagement is actually *for*. Is the dopamine pointing toward real progress, or just toward more engagement?

## What Makes Good Engagement Different

Some apps use similar mechanisms but feel different to use. What distinguishes engagement that serves you from engagement that extracts from you?

The first distinction is between finite goals and infinite loops. TikTok's feed never ends. There's no natural stopping point, no moment where you've "finished." Contrast this with an app like Couch to 5K, which guides you through a running program with a clear endpoint: the day you run 5 kilometers. Each session has a beginning and an end. The program itself has a beginning and an end. You're working toward something, not just consuming indefinitely.

The second distinction is between building real skills and simulating progress. Anki is a flashcard app that uses spaced repetition, showing you cards just before you'd forget them, which is one of the most validated techniques in memory research. It's less "fun" than Duolingo (no cute owl, no leaderboards, no XP) but the learning science is more robust. The engagement comes from watching yourself actually remember things you used to forget, not from accumulating points.

The third distinction is between user-controlled goals and platform-controlled metrics. In a productivity app like Todoist, you define what success looks like. You create the tasks, you decide when they're done, you set the priorities. The app is a tool that serves your goals. In TikTok, the platform defines success as more time spent. Your goals are irrelevant to the algorithm; the only metric is engagement.

The fourth distinction is transparency. Forest is an app that gamifies focus by growing virtual trees. When you start a focus session, a seed is planted. If you leave the app before the timer ends, the tree dies. Complete the session, and the tree grows. That's it. The mechanism is completely transparent. There's no mystery about why you feel motivated, no algorithmic optimization happening behind the scenes. The gamification is a tool you're consciously using, not a trick being played on you. Forest also plants real trees with the revenue from their app, which means your focus sessions have tangible real-world outcomes.

Underlying all of these is the question of whose interests the engagement serves. If you spend an hour on Strava, you probably ran or biked for an hour. The engagement is downstream of an activity that benefits you. If you spend an hour on TikTok, TikTok got an hour of your attention, and you got... what, exactly?

## Can You Apply This to Your Own Life?

This is where things get tricky, because the most effective engagement mechanisms work best when someone else designs them.

Variable rewards work because they're unpredictable. If you're giving yourself the rewards, you know what's coming. There's no prediction error, no dopamine spike from surprise. You can't really trick yourself into finding your own rewards variable. This is one reason why productivity "gamification" apps often fail: earning points you award yourself doesn't generate the same response as earning points in a system you don't control.

But you can apply some of the structural elements.

Setting external stopping points is one approach. If you're doing deep work, set a timer. The timer creates an endpoint that infinite digital tasks lack. The Pomodoro technique (25 minutes of work, 5 minute break) works partly because it imposes structure on tasks that would otherwise expand indefinitely. You're creating the finite goals that exploitative apps deliberately remove.

Making progress visible is another. Progress bars, completed task lists, word count trackers: these leverage the brain's sensitivity to advancement. The key is making sure the progress is toward something real, not just the accumulation of metrics. A word count matters if you're trying to finish a draft. A streak of days matters if each day involves actual practice.

You can also manipulate friction asymmetrically. You can't make your own rewards variable, but you can manipulate the effort required to access different activities. Make it easy to do what you want to do: lay out workout clothes the night before, keep healthy food visible and accessible, leave your writing document open. Make it hard to do what you don't: delete apps, put your phone in another room, use browser blockers.

Social accountability is perhaps the most powerful tool available. Working out with a friend, posting your writing publicly, committing to deadlines with collaborators: these create external pressure that pure self-motivation can't match. You're essentially outsourcing the enforcement mechanism to other people, which provides the external structure that self-gamification can't.

The test of a good system is whether time spent produces results you actually value. If you're "engaged" but not improving, learning, or achieving anything meaningful, the engagement is serving someone else's goals, or it's just making you feel productive while you spin in place.

---

# The Lever

The systems are ancient. The exploitation is modern. And now you know the difference.

You can't rewire your dopamine system. Hundreds of millions of years of evolution aren't going to yield to good intentions. But you can choose what it points at. You can design your environment so the easy behaviors are the good ones and the extractive ones require effort. You can notice the gap between wanting and liking, between the pull and the payoff.

The same mechanisms that keep you scrolling at 2am can help you learn a language, build a habit, or finish a project. The question isn't whether to engage your brain's reward systems.

It's who's holding the lever.

---

# Sources and Further Reading

## Foundational Neuroscience
- Schultz, W., Dayan, P., & Montague, P.R. (1997). "[A neural substrate of prediction and reward](https://www.science.org/doi/10.1126/science.275.5306.1593)." Science.
- Schultz, W. (1998). "[Predictive reward signal of dopamine neurons](https://journals.physiology.org/doi/full/10.1152/jn.1998.80.1.1)." Journal of Neurophysiology.
- Berridge, K.C. & Robinson, T.E. (2016). "[Liking, wanting, and the incentive-sensitization theory of addiction](https://pmc.ncbi.nlm.nih.gov/articles/PMC5171207/)." American Psychologist.

## On Variable Reinforcement and Gambling
- Ferster, C.B. & Skinner, B.F. (1957). *Schedules of Reinforcement*. Appleton-Century-Crofts.
- Clark, L. et al. (2009). "[Gambling near-misses enhance motivation to gamble and recruit win-related brain circuitry](https://pmc.ncbi.nlm.nih.gov/articles/PMC2658737/)." Neuron.
- Harrigan, K.A. (2008). "[Slot Machine Structural Characteristics: Creating Near Misses Using High Award Symbol Ratios](https://link.springer.com/article/10.1007/s11469-007-9066-8)." International Journal of Mental Health and Addiction.

## On Smartphone and Social Media Effects
- Ward, A.F. et al. (2017). "[Brain Drain: The Mere Presence of One's Own Smartphone Reduces Available Cognitive Capacity](https://www.journals.uchicago.edu/doi/full/10.1086/691462)." Journal of the Association for Consumer Research.
- Dekker, C.A. & Baumgartner, S.E. (2024). "[Is life brighter when your phone is not? The efficacy of a grayscale smartphone intervention](https://journals.sagepub.com/doi/10.1177/20501579231212062)." Mobile Media & Communication.

## On TikTok and Modern Platforms
- "[Does TikTok Addiction exist? A qualitative study](https://pmc.ncbi.nlm.nih.gov/articles/PMC11710882/)." PMC (2024).
- Brown University. "[What Makes TikTok so Addictive?](https://sites.brown.edu/publichealthjournal/2021/12/13/tiktok/)"

## On Treatment and Behavior Change
- "[Interventions for Digital Addiction: Umbrella Review of Meta-Analyses](https://www.jmir.org/2025/1/e59656)." Journal of Medical Internet Research (2025).

## Ethical Design
- Center for Humane Technology. "[humanetech.com](https://www.humanetech.com/)"
